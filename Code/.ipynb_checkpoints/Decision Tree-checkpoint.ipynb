{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can treat it as a regression problem because the the ordinal values for placement  represents continuous interval\n",
    "\n",
    "We cannot use multiclass (logistic regression) due to assumption (collinearity) \n",
    "    - 1vs all\n",
    "    \n",
    "GOAL : i want to know which team composition yield best placement.\n",
    "decision tree , tree based\n",
    "exboost\n",
    "\n",
    "go with pca?\n",
    "- dimensional reduction using feature extraction would be good for 'unit' combinations\n",
    "- explainability = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, precision_score, recall_score, f1_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Aatrox_1', 'Aatrox_2', 'Aatrox_3', 'Alchemist_1', 'Annie_1', 'Annie_2',\n",
       "       'Annie_3', 'Ashe_1', 'Ashe_2', 'Ashe_3',\n",
       "       ...\n",
       "       'Yasuo_3', 'Yorick_1', 'Yorick_2', 'Yorick_3', 'Zed_1', 'Zed_2',\n",
       "       'Zyra_1', 'Zyra_2', 'Zyra_3', 'placement'],\n",
       "      dtype='object', length=231)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/placement_traits_df.csv', index_col = 0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features & Target\n",
    "\n",
    "X = df.drop(['placement'], axis=1)\n",
    "y = df['placement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit for scaled data\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = ss.transform(X_train)\n",
    "Z_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdc = BaggingClassifier()\n",
    "bdc.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=False,\n",
       "                                            verbosity=None),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ovr = OneVsRestClassifier(XGBClassifier())\n",
    "xgb_ovr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Score: 0.9861005812484205\n",
      "Decision Tree Test Score: 0.20166793025018953\n",
      "---------------------------------------------\n",
      "Bagged Decision Trees Train Score: 0.974981046247157\n",
      "Bagged Decision Trees Test Score: 0.21834723275208492\n",
      "---------------------------------------------\n",
      "Random Forest Train Score: 0.9861005812484205\n",
      "Random Forest Test Score: 0.24260803639120546\n",
      "---------------------------------------------\n",
      "AdaBoost Train Score: 0.29214051048774325\n",
      "AdaBoost Test Score: 0.266868840030326\n",
      "---------------------------------------------\n",
      "XGBoost Train Score: 0.8589840788476119\n",
      "XGBoost Forest Test Score: 0.2441243366186505\n",
      "---------------------------------------------\n",
      "XGBoost + One Vs Rest Train Score: 0.8925954005559767\n",
      "XGBoost + One Vs Rest Test Score: 0.24639878695981804\n"
     ]
    }
   ],
   "source": [
    "print(f'Decision Tree Train Score: {dtc.score(Z_train, y_train)}')\n",
    "print(f'Decision Tree Test Score: {dtc.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "print(f'Bagged Decision Trees Train Score: {bdc.score(Z_train, y_train)}')\n",
    "print(f'Bagged Decision Trees Test Score: {bdc.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "print(f'Random Forest Train Score: {rfc.score(Z_train, y_train)}')\n",
    "print(f'Random Forest Test Score: {rfc.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "print(f'AdaBoost Train Score: {ada.score(Z_train, y_train)}')\n",
    "print(f'AdaBoost Test Score: {ada.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "print(f'XGBoost Train Score: {xgb.score(Z_train, y_train)}')\n",
    "print(f'XGBoost Forest Test Score: {xgb.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "print(f'XGBoost + One Vs Rest Train Score: {xgb_ovr.score(Z_train, y_train)}')\n",
    "print(f'XGBoost + One Vs Rest Test Score: {xgb_ovr.score(Z_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc = dtc.predict(Z_test)\n",
    "y_pred_bdc = bdc.predict(Z_test)\n",
    "y_pred_rfc = rfc.predict(Z_test)\n",
    "y_pred_ada = ada.predict(Z_test)\n",
    "y_pred_xgb = xgb.predict(Z_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-a24bb8acd09d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_dtc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 90\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Z_test, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-ad7bb6014eb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Decision Tree Test Score: {precision_score(y_test, y_pred_dtc)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Bagged Decision Trees Test Score: {bdc.score(Z_test, y_test)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1670\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1672\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1673\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1484\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m   1315\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                              % (y_type, average_options))\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Decision Tree Test Score: {precision_score(y_test, y_pred_dtc)}')\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(f'Bagged Decision Trees Test Score: {bdc.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(f'Random Forest Test Score: {rfc.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(f'AdaBoost Test Score: {ada.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(f'XGBoost Forest Test Score: {xgb.score(Z_test, y_test)}')\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print(f'XGBoost + One Vs Rest Test Score: {xgb_ovr.score(Z_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([627., 676., 599., 585., 649., 696., 676., 768.]),\n",
       " array([1.   , 1.875, 2.75 , 3.625, 4.5  , 5.375, 6.25 , 7.125, 8.   ]),\n",
       " <a list of 8 Patch objects>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.placement, bins= df.placement.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our dataset is imbalanced : more samples for placement = 8, less samples for placement = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation : https://medium.com/@b.terryjack/tips-and-tricks-for-multi-class-classification-c184ae1c8ffc\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label and multioutput targets are not supported by imbalance-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XX_train, XX_test = sm.fit_resample(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = pd.DataFrame(list(xgb.feature_importances_), columns = ['importance'], index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Taric_2               0.012586\n",
       "Avatar_1              0.011174\n",
       "MasterYi_2            0.009948\n",
       "Zed_2                 0.009873\n",
       "Olaf_2                0.009198\n",
       "                        ...   \n",
       "Ashe_3                0.000000\n",
       "Annie_3               0.000000\n",
       "Lucian_3              0.000000\n",
       "Set2_Blademaster_3    0.000000\n",
       "Twitch_3              0.000000\n",
       "Name: importance, Length: 230, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features['importance'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In broader sense, Regularization (as any means to prevent overfit) for Trees is done by:\n",
    "\n",
    "#limit max. depth of trees\n",
    "#ensembles / bag more than just 1 tree\n",
    "#set stricter stopping criterion on when to split a node further (e.g. min gain, number of samples etc.)\n",
    "#specifying how many minimum data points are needed at each node for splitting (There can be various similar criteria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 35}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_params = {'max_depth' : [5,10,20,35,50,70]}\n",
    "\n",
    "gs_dtc = GridSearchCV(dtc, param_grid = dtc_params, cv = 5)\n",
    "gs_dtc.fit(X_train, y_train)\n",
    "gs_dtc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=20, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_best = DecisionTreeClassifier(max_depth=20, random_state =42)\n",
    "dtc_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Score: 0.654030831437958\n",
      "Decision Tree Test Score: 0.21834723275208492\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'Decision Tree Train Score: {dtc_best.score(X_train, y_train)}')\n",
    "print(f'Decision Tree Test Score: {dtc_best.score(X_test, y_test)}')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 50}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_params = {'max_depth' : [5,10,20,35,50], # 20\n",
    "              'n_estimators' : [5,10,20,50]} #50 maybe check upwards?\n",
    "\n",
    "gs_rfc = GridSearchCV(rfc, param_grid = rfc_params, cv = 5)\n",
    "gs_rfc.fit(X_train, y_train)\n",
    "gs_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_best = RandomForestClassifier(max_depth=20, \n",
    "                         n_estimators=50, \n",
    "                         random_state =42)\n",
    "rfc_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Score: 0.9284811726055092\n",
      "Random Forest Test Score: 0.2577710386656558\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Random Forest Train Score: {rfc_best.score(X_train, y_train)}')\n",
    "print(f'Random Forest Test Score: {rfc_best.score(X_test, y_test)}')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 50}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = {'max_depth' : [5,10,20,35,50], # 5\n",
    "              'n_estimators' : [5,10,20,50]} # 50 maybe check upwards?\n",
    "\n",
    "gs_xgb = GridSearchCV(xgb, param_grid = xgb_params, cv = 5)\n",
    "gs_xgb.fit(X_train, y_train)\n",
    "gs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best = XGBClassifier(max_depth=5, \n",
    "                         n_estimators=50, \n",
    "                         random_state =42)\n",
    "xgb_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Train Score: 0.6606014657568865\n",
      "XGBoost Test Score: 0.244882486732373\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'XGBoost Train Score: {xgb_best.score(X_train, y_train)}')\n",
    "print(f'XGBoost Test Score: {xgb_best.score(X_test, y_test)}')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
